{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Inference on PYNQ with FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from driver import io_shape_dict\n",
    "from driver_base import FINNExampleOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(pred, conf_thresh=0.3, prob_thresh=0.01):\n",
    "    # https://github.com/motokimura/yolo_v1_pytorch\n",
    "    S, B, C = 7, 2, 20\n",
    "    boxes, labels, confidences, class_scores = [], [], [], []\n",
    "\n",
    "    cell_size = 1.0 / float(S)\n",
    "    conf = pred[:, :, 4] # [S, S, 1]\n",
    "    conf = np.expand_dims(conf,2)\n",
    "\n",
    "    for b in range(1, B):\n",
    "        conf = np.concatenate((conf, np.expand_dims(pred[:, :, 5*b + 4],2)), 2)\n",
    "    conf_mask = conf > conf_thresh # [S, S, B]\n",
    "\n",
    "    # TBM, further optimization may be possible by replacing the following for-loops with tensor operations.\n",
    "    for i in range(S): # for x-dimension.\n",
    "        for j in range(S): # for y-dimension.\n",
    "            class_label = np.argmax(pred[j, i, 5*B:], 0)\n",
    "            class_score = pred[j, i, 5*B:][class_label]\n",
    "            for b in range(B):\n",
    "                conf = pred[j, i, 5*b + 4]\n",
    "                prob = conf * class_score\n",
    "                if float(prob) < prob_thresh:\n",
    "                    continue\n",
    "\n",
    "                # Compute box corner (x1, y1, x2, y2) from tensor.\n",
    "                box = pred[j, i, 5*b : 5*b + 4]\n",
    "                x0y0_normalized = np.array([i, j]) * cell_size # cell left-top corner. Normalized from 0.0 to 1.0 w.r.t. image width/height.\n",
    "                xy_normalized = box[:2] * cell_size + x0y0_normalized   # box center. Normalized from 0.0 to 1.0 w.r.t. image width/height.\n",
    "                wh_normalized = box[2:] # Box width and height. Normalized from 0.0 to 1.0 w.r.t. image width/height.\n",
    "                box_xyxy = np.zeros(4) # [4,]\n",
    "                box_xyxy[:2] = xy_normalized - 0.5 * wh_normalized # left-top corner (x1, y1).\n",
    "                box_xyxy[2:] = xy_normalized + 0.5 * wh_normalized # right-bottom corner (x2, y2).\n",
    "\n",
    "                # Append result to the lists.\n",
    "                boxes.append(box_xyxy)\n",
    "                labels.append(class_label)\n",
    "                confidences.append(conf)\n",
    "                class_scores.append(class_score)\n",
    "\n",
    "    if len(boxes) > 0:\n",
    "        boxes = np.stack(boxes, 0) # [n_boxes, 4]\n",
    "        labels = np.stack(labels, 0)             # [n_boxes, ]\n",
    "        confidences = np.stack(confidences, 0)   # [n_boxes, ]\n",
    "        class_scores = np.stack(class_scores, 0) # [n_boxes, ]\n",
    "    else:\n",
    "        # If no box found, return empty tensors.\n",
    "        boxes = np.zeros(0, 4)\n",
    "        labels = np.zeros(0)\n",
    "        confidences = np.zeros(0)\n",
    "        class_scores = np.zeros(0)\n",
    "\n",
    "    return boxes, labels, confidences, class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, nms_thresh=0.5):\n",
    "    # https://github.com/motokimura/yolo_v1_pytorch\n",
    "    threshold = nms_thresh\n",
    "\n",
    "    x1 = boxes[:, 0] # [n,]\n",
    "    y1 = boxes[:, 1] # [n,]\n",
    "    x2 = boxes[:, 2] # [n,]\n",
    "    y2 = boxes[:, 3] # [n,]\n",
    "    areas = (x2 - x1) * (y2 - y1) # [n,]\n",
    "\n",
    "    ids_sorted = scores.argsort(0) # [n,]\n",
    "    ids_sorted = ids_sorted[::-1] \n",
    "    ids = []\n",
    "    while ids_sorted.size > 0:\n",
    "        # Assume `ids_sorted` size is [m,] in the beginning of this iter.\n",
    "\n",
    "        i = ids_sorted.item() if (ids_sorted.size == 1) else ids_sorted[0]\n",
    "        ids.append(i)\n",
    "\n",
    "        if ids_sorted.size == 1:\n",
    "            break # If only one box is left (i.e., no box to supress), break.\n",
    "\n",
    "        inter_x1 = x1[ids_sorted[1:]].clip(min=x1[i]) # [m-1, ]\n",
    "        inter_y1 = y1[ids_sorted[1:]].clip(min=y1[i]) # [m-1, ]\n",
    "        inter_x2 = x2[ids_sorted[1:]].clip(max=x2[i]) # [m-1, ]\n",
    "        inter_y2 = y2[ids_sorted[1:]].clip(max=y2[i]) # [m-1, ]\n",
    "        inter_w = (inter_x2 - inter_x1).clip(min=0) # [m-1, ]\n",
    "        inter_h = (inter_y2 - inter_y1).clip(min=0) # [m-1, ]\n",
    "\n",
    "        inters = inter_w * inter_h # intersections b/w/ box `i` and other boxes, sized [m-1, ].\n",
    "        unions = areas[i] + areas[ids_sorted[1:]] - inters # unions b/w/ box `i` and other boxes, sized [m-1, ].\n",
    "        ious = inters / unions # [m-1, ]\n",
    "\n",
    "        # Remove boxes whose IoU is higher than the threshold.\n",
    "        ids_keep = (ious <= threshold).nonzero()[0] # [m-1, ]. Because `nonzero()` adds extra dimension, squeeze it.\n",
    "        if ids_keep.size == 0:\n",
    "            break # If no box left, break.\n",
    "        ids_sorted = ids_sorted[ids_keep+1] # `+1` is needed because `ids_sorted[0] = i`.\n",
    "\n",
    "    return np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boxes(image_bgr, boxes, class_names, probs, name_bgr_dict=None, line_thickness=2):\n",
    "    # https://github.com/motokimura/yolo_v1_pytorch\n",
    "    if name_bgr_dict is None:\n",
    "        name_bgr_dict = VOC_CLASS_BGR\n",
    "\n",
    "    image_boxes = image_bgr.copy()\n",
    "    for box, class_name, prob in zip(boxes, class_names, probs):\n",
    "        # Draw box on the image.\n",
    "        left_top, right_bottom = box\n",
    "        left, top = int(left_top[0]), int(left_top[1])\n",
    "        right, bottom = int(right_bottom[0]), int(right_bottom[1])\n",
    "        bgr = name_bgr_dict[class_name]\n",
    "        cv2.rectangle(image_boxes, (left, top), (right, bottom), bgr, thickness=line_thickness)\n",
    "\n",
    "        # Draw text on the image.\n",
    "        text = '%s %.2f' % (class_name, prob)\n",
    "        size, baseline = cv2.getTextSize(text,  cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, thickness=2)\n",
    "        text_w, text_h = size\n",
    "\n",
    "        x, y = left, top\n",
    "        x1y1 = (x, y)\n",
    "        x2y2 = (x + text_w + line_thickness, y + text_h + line_thickness + baseline)\n",
    "        cv2.rectangle(image_boxes, x1y1, x2y2, bgr, -1)\n",
    "        cv2.putText(image_boxes, text, (x + line_thickness, y + 2*baseline + line_thickness),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4, color=(255, 255, 255), thickness=1, lineType=8)\n",
    "\n",
    "    return image_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([122.67891434,116.66876762,104.00698793],dtype=np.float32)\n",
    "\n",
    "# VOC class names and BGR color.\n",
    "VOC_CLASS_BGR = {\n",
    "    'aeroplane': (128, 0, 0),\n",
    "    'bicycle': (0, 128, 0),\n",
    "    'bird': (128, 128, 0),\n",
    "    'boat': (0, 0, 128),\n",
    "    'bottle': (128, 0, 128),\n",
    "    'bus': (0, 128, 128),\n",
    "    'car': (128, 128, 128),\n",
    "    'cat': (64, 0, 0),\n",
    "    'chair': (192, 0, 0),\n",
    "    'cow': (64, 128, 0),\n",
    "    'diningtable': (192, 128, 0),\n",
    "    'dog': (64, 0, 128),\n",
    "    'horse': (192, 0, 128),\n",
    "    'motorbike': (64, 128, 128),\n",
    "    'person': (192, 128, 128),\n",
    "    'pottedplant': (0, 64, 0),\n",
    "    'sheep': (128, 64, 0),\n",
    "    'sofa': (0, 192, 0),\n",
    "    'train': (128, 192, 0),\n",
    "    'tvmonitor': (0, 64, 128)\n",
    "}\n",
    "\n",
    "class_name_list = list(VOC_CLASS_BGR.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = FINNExampleOverlay(\n",
    "    bitfile_name=\"../bitfile/finn-accel.bit\",\n",
    "    platform=\"zynq-iodma\",\n",
    "    io_shape_dict=io_shape_dict,\n",
    "    batch_size=1,\n",
    "    runtime_weight_dir=\"runtime_weights/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"../../test_outputs/\"\n",
    "test_img_folder = \"../../test_samples/\"\n",
    "test_img_paths = glob.glob(test_img_folder + \"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number, test_img_path in enumerate(test_img_paths):\n",
    "    org_img = cv2.imread(test_img_path)\n",
    "    img = org_img.copy()\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    img = cv2.resize(org_img,(448,448), interpolation=cv2.INTER_LINEAR)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    \n",
    "    img = (img-mean)/255.0\n",
    "    img = img.astype(np.uint8)\n",
    "    driver_in = img.reshape(driver.ishape_normal)\n",
    "    print(\"Input buffer shape is %s and datatype is %s\" % (str(driver_in.shape), str(driver_in.dtype)))\n",
    "    \n",
    "    t1 = time.time()\n",
    "    output = driver.execute(driver_in)\n",
    "    t2 = time.time()\n",
    "    print(f\"Time passed for driver execution: {t2-t1} sec\")\n",
    "    print(f\"Output buffer shape is {output.shape} and datatype is {output.dtype}\")\n",
    "    #print(f\"Output: {output}\")\n",
    "\n",
    "    output = sigmoid(output)[0]\n",
    "    #print(f\"Output: {output}\")\n",
    "    \n",
    "    # Get detected boxes_detected, labels, confidences, class-scores.\n",
    "    boxes_normalized_all, class_labels_all, confidences_all, class_scores_all = decode(output)\n",
    "    \n",
    "    # Apply non maximum supression for boxes of each class.\n",
    "    boxes_normalized, class_labels, probs = [], [], []\n",
    "\n",
    "    for class_label in range(len(class_name_list)):\n",
    "        mask = (class_labels_all == class_label)\n",
    "        if np.sum(mask) == 0:\n",
    "            continue # if no box found, skip that class.\n",
    "\n",
    "        boxes_normalized_masked = boxes_normalized_all[mask]\n",
    "        class_labels_maked = class_labels_all[mask]\n",
    "        confidences_masked = confidences_all[mask]\n",
    "        class_scores_masked = class_scores_all[mask]\n",
    "\n",
    "        ids = nms(boxes_normalized_masked, confidences_masked)\n",
    "\n",
    "        boxes_normalized.append(boxes_normalized_masked[ids])\n",
    "        class_labels.append(class_labels_maked[ids])\n",
    "        probs.append(confidences_masked[ids] * class_scores_masked[ids])\n",
    "\n",
    "    boxes_normalized = np.concatenate(boxes_normalized, 0)\n",
    "    class_labels = np.concatenate(class_labels, 0)\n",
    "    probs = np.concatenate(probs, 0)\n",
    "    \n",
    "    # Postprocess for box, labels, probs.\n",
    "    boxes_detected, class_names_detected, probs_detected = [], [], []\n",
    "    for b in range(boxes_normalized.shape[0]):\n",
    "        box_normalized = boxes_normalized[b]\n",
    "        class_label = class_labels[b]\n",
    "        prob = probs[b]\n",
    "\n",
    "        x1, x2 = w * box_normalized[0], w * box_normalized[2] # unnormalize x with image width.\n",
    "        y1, y2 = h * box_normalized[1], h * box_normalized[3] # unnormalize y with image height.\n",
    "        boxes_detected.append(((x1, y1), (x2, y2)))\n",
    "\n",
    "        class_label = int(class_label) \n",
    "        class_name = class_name_list[class_label]\n",
    "        class_names_detected.append(class_name)\n",
    "\n",
    "        prob = float(prob)\n",
    "        probs_detected.append(prob)\n",
    "    \n",
    "    # Visualize.\n",
    "    image_boxes = visualize_boxes(org_img, boxes_detected, class_names_detected, probs_detected)\n",
    "    cv2.imwrite(output_folder+f\"{number}.jpg\", image_boxes)\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(image_boxes, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "print(driver.throughput_test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
